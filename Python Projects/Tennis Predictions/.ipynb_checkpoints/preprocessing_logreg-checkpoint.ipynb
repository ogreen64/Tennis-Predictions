{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952b6ff5-d5af-44c3-9684-e0c7e08bd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facbdc51-976e-48d3-97ec-85f4d276aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c1f677-b2f4-460c-a404-f93849bf881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(X, y, X_train):\n",
    "    # These features are strings when they should be numeric\n",
    "    wrong_fts = [feature for feature in ['P1 Rank', 'P2 Rank', 'P1 Set 2', 'P2 Set 2', 'P1 Set 3', 'P2 Set 3'] if feature in X]\n",
    "    for feature in wrong_fts:\n",
    "        X.loc[:, feature] = pd.to_numeric(X[feature], errors = 'coerce')\n",
    "    # These features are very rarely missing so we can just drop the rows\n",
    "    drop_fts = [feature for feature in ['Best of', 'P1 Rank', 'P2 Rank'] if feature in X]\n",
    "    drop_rows = X[drop_fts].isna().any(axis = 1)\n",
    "    drop_rows_indices = X.index[drop_rows]\n",
    "    X = X.drop(drop_rows_indices).reset_index(drop = True)\n",
    "    y = y.drop(drop_rows_indices).reset_index(drop = True)\n",
    "    # These features are usually missing due to a walkover so it doesn't make much sense to fill them with anything other than 0\n",
    "    fill_fts = [feature for feature in ['P1 Set 1', 'P2 Set 1', 'P1 Set 2', 'P2 Set 2',\n",
    "                                        'P1 Set 3', 'P2 Set 3', 'P1 Set 4', 'P2 Set 4'] if feature in X]\n",
    "    X.loc[:, fill_fts] = X[fill_fts].fillna(0)\n",
    "    # These features are usually missing due to time so we just give a mean value\n",
    "    mean_fts = [feature for feature in ['P1 Pts', 'P2 Pts', 'B365 P1', 'B365 P2', 'PS P1', 'PS P2'] if feature in X]\n",
    "    for feature in mean_fts:\n",
    "        ft_mean = X_train[feature].mean()\n",
    "        X.loc[:, feature] = X[feature].fillna(ft_mean)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf29e8ad-5a8e-4e1f-bc58-07df8e45836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(X, X_train):\n",
    "    encoder = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "    encoder.fit(X_train)\n",
    "    X = encoder.transform(X)\n",
    "    X = pd.DataFrame(X, columns = X_train.columns)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201a3619-edc5-42bb-965d-46a0cce95d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X, X_train):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X = X.astype(float)\n",
    "    X = scaler.transform(X)\n",
    "    X = pd.DataFrame(X, columns = X_train.columns)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3241bcb4-7088-4ed9-9c44-cdab2fd53791",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fts = ['Location', 'Tournament', 'Series', 'Court', 'Surface', 'Round', 'Player 1', 'Player 2', 'Comment']\n",
    "num_fts = ['ATP', 'Best of', 'P1 Rank', 'P2 Rank', 'P1 Pts', 'P2 Pts', 'B365 P1', 'B365 P2', 'PS P1', 'PS P2', 'Day', 'Month', 'Year']\n",
    "mid_match_fts = ['P1 Set 1', 'P2 Set 1', 'P1 Set 2', 'P2 Set 2', 'P1 Set 3', 'P2 Set 3', 'P1 Set 4', 'P2 Set 4']\n",
    "# Uncomment below to include mid-match features in model (only use when predicting a live match)\n",
    "# num_fts = num_fts + mid_match_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4d22ca-e714-44cf-8332-b88ba3a7cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv')\n",
    "X = df[num_fts + cat_fts]\n",
    "y = df['Result']\n",
    "X_train = X.loc[df['Year'] < df['Year'].max()]\n",
    "# We must clean X, y, and X_train to ensure our data is consistent and to prepare for encoding\n",
    "X, y = clean(X, y, X_train)\n",
    "# We want to keep y at its current state so we store the y output of the function to the variable 'unused'\n",
    "X_train, unused = clean(X_train, y, X_train)\n",
    "# We must encode X and X_train to prepare for scaling\n",
    "X[cat_fts] = ordinal_encode(X[cat_fts], X_train[cat_fts])\n",
    "X_train[cat_fts] = ordinal_encode(X_train[cat_fts], X_train[cat_fts])\n",
    "# We only have to scale X as we are done with X_train\n",
    "X = scale(X, X_train)\n",
    "df = pd.concat([X, y], axis = 1)\n",
    "df.to_csv('preprocessed_df_logreg.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
